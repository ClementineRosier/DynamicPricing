{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from scipy.stats import norm, beta, bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/clementine.rosier/OneDrive - Ekimetrics/Documents/GitHub/dynamic_pricing\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple simulations\n",
    "from src.simulations import SimpleSimulation\n",
    "from src.simulation_melange_gaussien import GMixSimulation\n",
    "from src.simulation_uniforme import UniformSimulation\n",
    "#simulations with context\n",
    "from src.context_generator import ContextGenerator\n",
    "from src.simulation_with_context import ContextualDemandSimulation\n",
    "#bandit algo\n",
    "from src.binomial_bandit import BinomialBandit\n",
    "from src.simple_bandit_greedy import GreedyBandit\n",
    "from src.simple_bandit_ucb import UCBBandit\n",
    "from src.context_bandit import ContextBandit\n",
    "#evaluation algo (regret)\n",
    "from src.evaluate_model import EvaluateBandit\n",
    "from src.evaluate_with_context import EvaluateBanditContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demand_context(simulation,context_generator, min_price = 0, max_price = 150, n_points = 50, n_estimates_per_point = 100) : \n",
    "    prices = []\n",
    "    revenues = []\n",
    "    for price in np.linspace(min_price, max_price, n_points) : \n",
    "        context_c, context_d = context_generator.simulate()\n",
    "        revenues.extend( [simulation.evaluate(price,context_c, context_d) * price for x in range(n_estimates_per_point)] )\n",
    "        prices.extend([price for x in range(n_estimates_per_point)])\n",
    "    \n",
    "    a = np.array([prices, revenues])\n",
    "\n",
    "    fig = plt.figure(figsize = (15,6), facecolor=\"w\")\n",
    "    ax = sns.lineplot(a[0], a[1])\n",
    "    ax.legend(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bandit_thompson(simulation,k_p, alpha_0, beta_0,init_round=10,test_round=5000):\n",
    "    hist = []\n",
    "    regret = []\n",
    "    reward_T = []\n",
    "    parameters=np.array([np.array([alpha_0]),np.array([beta_0])])\n",
    "    bandit = BinomialBandit(k_p, alpha_0, beta_0)\n",
    "    evaluation=EvaluateBandit(bandit,simulation)\n",
    "    print(evaluation.best_price)\n",
    "    # Exploration round\n",
    "    for i in range(init_round):\n",
    "        for j in range(bandit.k):\n",
    "            bandit.chose_action(force_action=j)\n",
    "            price = k_p[bandit.action]\n",
    "            reward = int(simulation.evaluate(price)) * price\n",
    "            bandit.update(bandit.action, reward)\n",
    "            regret.append(evaluation.get_regret(bandit.n_obs))\n",
    "            parameters = np.append(parameters,np.array([np.array([bandit.alpha_n]),np.array([bandit.beta_n])]),axis=1)\n",
    "\n",
    "    for i in range(test_round):\n",
    "        bandit.chose_action(method=\"thompson\")\n",
    "        price = k_p[bandit.action]\n",
    "        reward = int(simulation.evaluate(price)) * price\n",
    "        bandit.update(bandit.action, reward)\n",
    "        regret.append(evaluation.get_regret(bandit.n_obs))\n",
    "        hist.append(k_p[bandit.action])\n",
    "        parameters = np.append(parameters,np.array([np.array([bandit.alpha_n]),np.array([bandit.beta_n])]),axis=1)\n",
    "    return hist,regret,parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simplebandit_context(simulation,k_p, alpha_0, beta_0,init_round,test_round):\n",
    "    hist = []\n",
    "    regret = []\n",
    "    reward_T = []\n",
    "    parameters=np.array([np.array([alpha_0]),np.array([beta_0])])\n",
    "    bandit = BinomialBandit(k_p, alpha_0, beta_0)\n",
    "    evaluation=EvaluateBanditContext(bandit,simulation)\n",
    "    # Exploration round\n",
    "    for i in range(init_round):\n",
    "        for j in range(bandit.k):\n",
    "            context_c, context_d = context_generator.simulate()\n",
    "            bandit.chose_action(force_action=j)\n",
    "            price = k_p[bandit.action]\n",
    "            reward = int(simulation.evaluate(price,context_c, context_d)) * price\n",
    "            bandit.update(bandit.action, reward)\n",
    "            regret.append(evaluation.get_regret(bandit.n_obs,bandit.action,context_c, context_d))\n",
    "            parameters = np.append(parameters,np.array([np.array([bandit.alpha_n]),np.array([bandit.beta_n])]),axis=1)\n",
    "\n",
    "    for i in range(test_round):\n",
    "        context_c, context_d = context_generator.simulate()\n",
    "        bandit.chose_action(method=\"thompson\")\n",
    "        price = k_p[bandit.action]\n",
    "        reward = int(simulation.evaluate(price,context_c, context_d)) * price\n",
    "        bandit.update(bandit.action, reward)\n",
    "        regret.append(evaluation.get_regret(bandit.n_obs,bandit.action,context_c, context_d))\n",
    "        hist.append(bandit.action)\n",
    "        parameters = np.append(parameters,np.array([np.array([bandit.alpha_n]),np.array([bandit.beta_n])]),axis=1)\n",
    "    return hist,regret,parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_contextualbandit_context(simulation,size_context,m_0,q_0,init_round,test_round):\n",
    "    hist = []\n",
    "    regret = []\n",
    "    reward_T = []\n",
    "    parameters=np.array([np.array([m_0]),np.array([q_0])])\n",
    "    bandit = ContextBandit(k_p,size_context,m_0,q_0)\n",
    "    evaluation=EvaluateBanditContext(bandit,simulation)\n",
    "    # Exploration round\n",
    "    for i in range(init_round):\n",
    "        for j in range(bandit.k):\n",
    "            context_c, context_d = context_generator.simulate()\n",
    "            bandit.chose_action(force_action=j)\n",
    "            price = k_p[bandit.action]\n",
    "            reward = int(simulation.evaluate(price,context_c, context_d)) * price\n",
    "            regret.append(evaluation.get_regret(bandit.n_obs,bandit.action,context_c, context_d))\n",
    "            bandit.update(bandit.action, reward)\n",
    "            parameters = np.append(parameters,np.array([np.array([bandit.m_n]),np.array([bandit.q_n])]),axis=1)\n",
    "\n",
    "    for i in range(test_round):\n",
    "        context_c, context_d = context_generator.simulate()\n",
    "        bandit.chose_action(method=\"thompson\")\n",
    "        price = k_p[bandit.action]\n",
    "        reward = int(simulation.evaluate(price,context_c, context_d)) * price\n",
    "        regret.append(evaluation.get_regret(bandit.n_obs,bandit.action,context_c, context_d))\n",
    "        bandit.update(bandit.action, reward)\n",
    "        hist.append(bandit.action)\n",
    "        parameters = np.append(parameters,np.array([np.array([bandit.m_n]),np.array([bandit.q_n])]),axis=1)\n",
    "    return hist,regret,parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_c=np.array([0])\n",
    "mu_c=np.array([0])\n",
    "sigma_c=np.array([1])\n",
    "beta_d=np.array([[1,-1,7],[2,100,-1,8,-40]])\n",
    "n=np.array([3,5])\n",
    "mu_e=-200\n",
    "sigma_e=15\n",
    "#instantiate context simulation\n",
    "context_generator_discret = ContextGenerator(mu_c,sigma_c,n)\n",
    "\n",
    "#instantiate demand simulation\n",
    "demand_simulation_discret = ContextualDemandSimulation(beta_c, beta_d, mu_e, sigma_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demand_context(demand_simulation_discret,context_generator_discret)\n",
    "plt.title('Simulation du revenu avec contexte (variables discr√®tes)')\n",
    "plt.xlabel('prix')\n",
    "plt.ylabel('revenu')\n",
    "plt.savefig('demand_context_disc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_c=np.array([2,-5,2])\n",
    "mu_c=np.array([50,4,30])\n",
    "sigma_c=np.array([1,4,20])\n",
    "beta_d=np.array([[1]])\n",
    "n=np.array([1])\n",
    "mu_e=-200\n",
    "sigma_e=15\n",
    "#instantiate context simulation\n",
    "context_generator_cont = ContextGenerator(mu_c,sigma_c,n)\n",
    "\n",
    "#instantiate demand simulation\n",
    "demand_simulation_cont = ContextualDemandSimulation(beta_c, beta_d, mu_e, sigma_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demand_context(demand_simulation_cont,context_generator_cont)\n",
    "plt.title('Simulation du revenu avec contexte (variables continues)')\n",
    "plt.xlabel('prix')\n",
    "plt.ylabel('revenu')\n",
    "plt.savefig('demand_context_cont.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_c=np.array([2,-5,2])\n",
    "mu_c=np.array([50,4,30])\n",
    "sigma_c=np.array([1,4,20])\n",
    "beta_d=np.array([[1,-1,7],[2,100,-1,8,-40]])\n",
    "n=np.array([3,5])\n",
    "mu_e=-200\n",
    "sigma_e=15\n",
    "#instantiate context simulation\n",
    "context_generator_all = ContextGenerator(mu_c,sigma_c,n)\n",
    "\n",
    "#instantiate demand simulation\n",
    "demand_simulation_all = ContextualDemandSimulation(beta_c, beta_d, mu_e, sigma_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demand_context(demand_simulation_all,context_generator_all)\n",
    "plot_demand_context(demand_simulation_cont,context_generator_cont)\n",
    "plt.title('Simulation du revenu avec contexte')\n",
    "plt.xlabel('prix')\n",
    "plt.ylabel('revenu')\n",
    "plt.savefig('demand_context_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test des algorithmes thompson sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_p="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate for contextual bandit\n",
    "norm_mean = 0\n",
    "norm_std = 1\n",
    "m_0 = np.zeros(shape=(len(k_p),size_context)) + norm_mean\n",
    "q_0 = np.zeros(shape=(len(k_p),size_context)) + norm_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
